{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "color-louisiana",
   "metadata": {},
   "source": [
    "#### Lecture 1. 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-cholesterol",
   "metadata": {},
   "source": [
    "미분(differentiation) : 변수의 움직임에 따른 함수값의 변화, 접선의 기울기, 변화율의 극한\n",
    "- 접선의 기울기를 알면 점이 움직이는 방향에 따른 함수값의 증감을 알 수 있음\n",
    "- 변수에 미분값을 더해주면 함수값이 증가(경사상승), 빼주면 감소(경사하강)\n",
    "- 경사상승/경사하강은 극값(미분값이 0)에 도달하면 움직임을 멈춤\n",
    "- 변수가 벡터일 때 : 편미분 사용\n",
    "- 각 변수 별로 편미분을 계산한 gradient vector 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dental-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "scientific-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.abc import x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indoor-balloon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\operatorname{Poly}{\\left( 2 x + 2, x, domain=\\mathbb{Z} \\right)}$"
      ],
      "text/plain": [
       "Poly(2*x + 2, x, domain='ZZ')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.diff(sym.poly(x**2 + 2*x + 3), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grateful-sleep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수: Poly(x**2 + 2*x + 5, x, domain='ZZ'), 연산횟수: 615, 최소점: (-0.999995080871606,4.00000000002420)\n"
     ]
    }
   ],
   "source": [
    "def func(val):\n",
    "    fun = sym.poly(x**2 + 2*x + 5)\n",
    "    return fun.subs(x, val), fun\n",
    "\n",
    "def func_gradient(fun, val):\n",
    "    _, function = fun(val)\n",
    "    diff = sym.diff(function, x)\n",
    "    return diff.subs(x, val), diff\n",
    "\n",
    "def gradient_descent(fun, init_point, lr_rate = 1e-2, epsilon=1e-5):\n",
    "    cnt = 0\n",
    "    val = init_point\n",
    "    diff, _ = func_gradient(fun, init_point)\n",
    "    while np.abs(diff) > epsilon:\n",
    "        val = val - lr_rate*diff\n",
    "        diff, _ = func_gradient(fun, val)\n",
    "        cnt += 1\n",
    "    print(\"함수: {}, 연산횟수: {}, 최소점: ({},{})\".format(fun(val)[1], cnt, val, fun(val)[0]))\n",
    "\n",
    "gradient_descent(fun=func, init_point=np.random.uniform(-3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "standard-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinwo\\miniconda3\\envs\\project\\lib\\site-packages\\sympy\\polys\\polytools.py:75: SymPyDeprecationWarning: \n",
      "\n",
      "Mixing Poly with non-polynomial expressions in binary operations has\n",
      "been deprecated since SymPy 1.6. Use the as_expr or as_poly method to\n",
      "convert types instead. See https://github.com/sympy/sympy/issues/18613\n",
      "for more info.\n",
      "\n",
      "  SymPyDeprecationWarning(\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2 x + 2 y - \\sin{\\left(x + 2 y \\right)}$"
      ],
      "text/plain": [
       "2*x + 2*y - sin(x + 2*y)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym.diff(sym.poly(x**2 + 2*x*y + 3) + sym.cos(x + 2*y), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-fifteen",
   "metadata": {},
   "source": [
    "경사하강법으로 선형회귀 계수 구하기\n",
    "- 선형회귀 목적식 $ \\lVert y-X\\beta \\rVert_2 $ 이고 이를 최소화하는 $\\beta$를 구하기 위해서\n",
    "- $ \\nabla\\beta \\lVert y-X\\beta \\rVert_2 = ( \\partial\\beta_1\\lVert y-X\\beta \\rVert_2, ... , \\partial\\beta_d\\lVert y-X\\beta \\rVert_2) = -\\frac{X^T(y-X\\beta)}{n\\lVert y-X\\beta \\rVert_2}  $\n",
    "- 목적식을 최소화하는 경사하강법 알고리즘\n",
    "    - $\\beta^{(t+1)} \\leftarrow \\beta^{(t)} - \\lambda\\nabla\\beta\\lVert y-X\\beta^{(t)}\\rVert $\n",
    "- 종료조건을 일정학습횟수로 변경하는 점만 빼면 앞의 경사하강법 알고리즘과 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "narrow-housing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000003  1.99999996 2.99999961]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,1], [1,2], [2,2], [2,3]])\n",
    "y = np.dot(X, np.array([1,2])) + 3\n",
    "beta_gd = [25.1, 12.3, -4.7] # 초기값\n",
    "X_ = np.array([np.append(x, [1]) for x in X]) # intercept 항 추가\n",
    "\n",
    "for t in range(1000): # 학습 횟수가 너무 적으면 안됨\n",
    "    error = y - X_ @ beta_gd  # @ : 행렬곱\n",
    "    # error = error / np.linalg.norm(error)\n",
    "    grad = -np.transpose(X_) @ error\n",
    "    beta_gd = beta_gd - 0.06 * grad   # 학습률이 일정 범위가 넘으면 발산\n",
    "\n",
    "print(beta_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-baltimore",
   "metadata": {},
   "source": [
    "- 미분가능하고 볼록(convex) 함수에 대해 적절 학습률과 학습 횟수를 선택했을때 수렴 보장\n",
    "- 선형회귀는 볼록함수 이므로 수렴이 보장되나 딥러닝 목적식은 대부분은 볼록함수가 아님"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-device",
   "metadata": {},
   "source": [
    "확률적 경사하강법(SGD : stochastic gradient descent)\n",
    "- 볼록이 아닌(non-convex) 목적식을 최적화 할 때(딥러닝 학습에 효율적)\n",
    "- 데이터를 한개만 사용하는 경우(SGD) / 여러개 사용(mini batch SGD)\n",
    "- 데이터를 일부만 가지고 파라미터를 업데이트 하므로 연산자원을 효율적을 활용\n",
    "- 미니배치를 확률적으로 선택하므로 목적식 모양이 바뀌게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-senior",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
