{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rubber-mustang",
   "metadata": {},
   "source": [
    "#### Lecture 1. 페이지 랭크"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-closure",
   "metadata": {},
   "source": [
    "1. 웹과 그래프\n",
    "- 웹 : 웹페이지(정점)와 하이퍼링크(간선)로 구성된 거대한 방향성 있는 그래프\n",
    "- 초창기 검색엔진\n",
    "    - 1st : 웹을 거대한 디렉토리로 정리 하였으나 카테고리의 수와 깊이가 무한\n",
    "    - 2nd : 키워드에 의존한 검색 엔진, 악의적인 웹페이지에 취약\n",
    "    - 구글에서 pagerank 를 개발하여 키워드와 관련성, 신뢰성이 높은 웹페이지 검색\n",
    "\n",
    "2. 페이지랭크\n",
    "- 페이지랭크의 핵심 아이디어는 투표, 웹페이지가 하이퍼 링크를 통해 투표함\n",
    "- 들어오는 간선의 수를 조작하는 문제를 해결하기 위해 가중투표 도입\n",
    "    - 관련성이 높고 신뢰할 수 있는 웹사이트의 투표를 더 중요하게 간주\n",
    "    - 각 웹페이지가 이웃에게 $ \\frac{자신의 페이지 랭크 점수}{나가는 이웃의 수}$ 만큼의 가중치로 투표\n",
    "    - 페이지 랭크 점수 $ r_j = \\sum_{i \\in N_{in}(j)}\\frac{r_i}{d_{out}(i)}$\n",
    "- 임의 보행(random walk) 관점의 정의\n",
    "    - 웹서퍼가 t번째 방문한 웹페이지가 웹페이지 i일 확률 $p_i(t)$\n",
    "    - $p_i(t)$ 는 길이가 웹페이지 수와 같은 확률분포 벡터가 됨\n",
    "    - 균일한 확률로 웹서핑이 이루어진다면 $ p_j(t+1) = \\sum_{i \\in N_{in}(j)}\\frac{p_i(t)}{d_{out}(i)}$\n",
    "    - t가 무한히 커지면 $p(t)=p(t+1)=p$  $ p_j = \\sum_{i \\in N_{in}(j)}\\frac{p_i}{d_{out}(i)}$\n",
    "    - 투표관점 페이지 랭크 점수와 임의 보행 관점 정상 분포가 동일\n",
    "\n",
    "3. 페이지랭크의 계산\n",
    "- 반복곱(Power Iteration)\n",
    "    - 페이지랭크 점수 $r_i^{(0)}$ 를 1/(웹페이지)의 수로 초기화\n",
    "    - $ p_j(t+1) = \\sum_{i \\in N_{in}(j)}\\frac{p_i(t)}{d_{out}(i)}$ 로 페이지 랭크 점수 갱신하고 수렴시 종료\n",
    "    - 반복곱의 수렴 보장 X (spider trap : 들어온는 간선만 있는 정점 집합 시 진동)\n",
    "    - 합리적인 점수 수렴 X (dead end : 막다른 정점 의 경우 모두 0으로 수렴)\n",
    "- 단순 임의 보행 해결을 위해 teleport 도입\n",
    "    - 현재 웹페이지에 하이퍼링크가 없다면 임의의 웹페이지로 순간이동\n",
    "    - 하이퍼링크가 있다면 $\\alpha$ 의 확률로 임의 보행, $1- \\alpha$ 의 확률로 순간이동\n",
    "    - $\\alpha$ : 감폭비율(damping factor, 보통 0.8)\n",
    "- teleport 계산\n",
    "    - 각 막다른 정점에서 자신을 포함하는 모든 정점으로 가는 간선 추가\n",
    "    - $ r_j = \\sum_{i \\in N_{in}(j)}\\alpha\\frac{r_i}{d_{out}(i)} + (1-\\alpha)\\frac{1}{|V|}$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-allen",
   "metadata": {},
   "source": [
    "#### Lecture 2. 그래프를 통한 전파 모형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-navigator",
   "metadata": {},
   "source": [
    "그래프 상의 정보, 행동, 고장, 질병 등의 전파를 수학적 모형으로 설명\n",
    "1. 의사결정 기반 전파 모형\n",
    "- 주변사람들의 의사결졍을 고려하여 각자 의사결정을 내리는 경우\n",
    "- 선형 임계치 모형(linear threshold model)\n",
    "    - p 비율의 이웃과 상호작용하여 얻는 효용 a / 1-p 비율의 이웃과의 효용 b이고\n",
    "    - a,b 가 호환되지 않을 때 a를 선택하는 경우는 ap > b(1-p) 일 때\n",
    "    - 즉, p > $\\frac{b}{a+b}$ 일 때 이며 $\\frac{b}{a+b}$ 가 임계치 q\n",
    "    - b가 시장을 지배하고 a가 early adapter일 때 전파 과정을 볼 수 있음\n",
    "2. 확률적 전파 모형\n",
    "- 질병의 전파처럼 의사결정에 의한 것이 아니라 확률적으로 전파가 일어나는 경우\n",
    "- 독립적 전파 모형\n",
    "    - 서로 다른 이웃이 전염되는 확률은 독립적\n",
    "    - 감염자는 계속 감염자 상태로 남아있는 것을 가정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-policy",
   "metadata": {},
   "source": [
    "3. 바이럴 마케팅과 전파 최대화\n",
    "- 바이럴 마케팅 : 긍정적인 입소문을 내게 하는 기법으로 소문의 시작점이 중요\n",
    "- 앞의 전파 모형역시 시드 집합이 전파 크기에 많은 영향을 미침\n",
    "- 전파 최대화 : 그래프, 전파 모형, 시드 집합의 크기가 주어질 때 전파를 최대화하는 시드 집합 찾기\n",
    "- NP-hard 문제로 그래프의 크기가 커지면 최적해를 찾는 것은 불가능 => 휴리스틱\n",
    "- 휴리스틱 : 실험적으로는 잘 동작하지만 이론적으로는 보장 불가한 이론\n",
    "- 정점의 중심성이 높은 순으로 시드 집합의 크기 k 만큼의 정점을 선택\n",
    "- greedy algorithm : 시드집합의 크기를 1에서 부터 하나씩 늘려가면서 시뮬레이션하여 전파 크기가 최대가 되는 원소를 하나씩 추가하는 방식\n",
    "    - 독립전파 모형의 경우 탐욕알고리즘으로 찾은 시드 집합에 의한 전파의 평균 크기 >= (1-1/e) * 최고의 시드 집합에 의한 전파의 평균 크기\n",
    "    - 최저 성능은 수학적으로 보장됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-spare",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
