{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "integrated-nudist",
   "metadata": {},
   "source": [
    "#### Lecture 1. 행렬 분해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-invite",
   "metadata": {},
   "source": [
    "##### mini code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mental-cannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9963000000018987 is close enough to the cube root of 27\n"
     ]
    }
   ],
   "source": [
    "# epsilon approximation\n",
    "guess = 0.0\n",
    "cube = 27\n",
    "increment = 0.0001\n",
    "epsilon = 0.1\n",
    "\n",
    "while abs(guess ** 3 - cube) >= epsilon:\n",
    "    guess += increment\n",
    "\n",
    "print('{} is close enough to the cube root of {}'.format(guess, cube))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confused-hollow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W matrix: \n",
      " [[0.01 0.66]\n",
      " [0.01 1.15]\n",
      " [0.   3.69]\n",
      " [3.05 0.  ]\n",
      " [2.87 0.  ]] \n",
      "\n",
      "H matrix: \n",
      " [[0.   0.   3.54 2.21 0.34]\n",
      " [2.2  3.22 0.   0.   0.36]] \n",
      "\n",
      "Approximated matrix: \n",
      " [[ 1.458  2.136  0.052  0.033  0.242]\n",
      " [ 2.528  3.705  0.04   0.025  0.415]\n",
      " [ 8.113 11.888  0.     0.     1.319]\n",
      " [ 0.003  0.    10.788  6.733  1.032]\n",
      " [ 0.003  0.001 10.164  6.344  0.972]] \n",
      "\n",
      "Original matrix: \n",
      " [[ 3  1  0  0  1]\n",
      " [ 2  4  0  0  1]\n",
      " [ 8 12  0  0  1]\n",
      " [ 0  0 10  8  1]\n",
      " [ 0  0 11  5  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinwo\\miniconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:315: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  \"'nndsvda' in 1.1 (renaming of 0.26).\"), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# NMF : Non-negative Matrix Factorization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'Doc1':[3, 2, 8, 0, 0],\n",
    "                   'Doc2':[1, 4, 12, 0, 0],\n",
    "                   'Doc3':[0, 0, 0, 10, 11],\n",
    "                   'Doc4':[0, 0, 0, 8, 5],\n",
    "                   'Doc5':[1, 1, 1, 1, 1]},\n",
    "                   index = ['col0', 'col1', 'col2', 'col3', 'col4'])\n",
    "\n",
    "from sklearn import decomposition\n",
    "model = decomposition.NMF(2)\n",
    "original = df.values\n",
    "W = model.fit_transform(original)\n",
    "H = model.components_\n",
    "print('W matrix: \\n', W.round(2), '\\n')\n",
    "print('H matrix: \\n', H.round(2), '\\n')\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "approx = np.round(np.dot(W, H), 3)\n",
    "print(\"Approximated matrix: \\n\", approx, '\\n')\n",
    "print(\"Original matrix: \\n\", original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-bahamas",
   "metadata": {},
   "source": [
    "1. maps\n",
    "- Matrix(Tensor) is a data modeling tool\n",
    "- Matrix(Tensor) is a linear transformation\n",
    "    - 선형 변환 : 변환 후 벡터의 덧셈과 스칼라곱을 보존하는 변환\n",
    "- terminology\n",
    "    - filter decomposition : 필터를 나타내는 데이터의 분해 (conv. layer)\n",
    "    - matrix factorization : 2차원으로 데이터 분해\n",
    "    - tensor factorization : 고차원으로 데이터 분해\n",
    "- Gaussian elimination\n",
    "    - basis : matrix의 선형공간을 정의하는 기본단위가 되는 벡터의 set\n",
    "    - basis 끼리는 linearly independent\n",
    "\n",
    "2. kernel method\n",
    "- kernel : central essential part\n",
    "- filter decomposition : depth-wise separable convolution\n",
    "\n",
    "3. matrix decomposition\n",
    "- eigenvalue decompostion, SVD(singular value decomposition) $ A = U\\sum V^T $\n",
    "- eigenvector : 변환 후에 방향이 보존되는 벡터(크기 변화는 eigenvalue)\n",
    "- SVD 는 정방행렬(n x n matrix) 가 아니라도 적용가능\n",
    "- PCA는 SVD와 유사하나 정보손실과 차원 축소가 일어남\n",
    "\n",
    "4. tensor decomposition\n",
    "- CP(canonical polyadic) decomposition\n",
    "- CP model / Tucker model\n",
    "- Tensor Componets Analysis(TCA)\n",
    "- MobileNet block은 CP convolution의 특이 케이스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-convention",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-fluid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
