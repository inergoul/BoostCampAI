{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "racial-address",
   "metadata": {},
   "source": [
    "#### Lecture 1. Generative model 1\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-knight",
   "metadata": {},
   "source": [
    "generative model\n",
    "- What I cannot create I do not understand(by Richard Feynman)\n",
    "- Generation : sampling model 만들기(생성 기능\n",
    "- Density estimation : 이상 감지(anomaly detection), 확률추정가능(explicit model)\n",
    "- Unsupervised representation learning : feature 학습\n",
    "\n",
    "각각의 확률이 독립적임을 가정했을 때의 강력한 변화\n",
    "- ex) binary(wxh) image 경우의 수 2<sup>n</sup>  (n = wxh), parameter 수 2<sup>n</sup> - 1\n",
    "    - 각각의 pixel이 독립적이라고 가정하면 parameter 수 n (매우 줄어듬)\n",
    "    - 하지만 독립적으로 표현할 수 있는 이미지는 noise뿐 (중간 지점 필요)\n",
    "    \n",
    "세가지 원칙\n",
    "- Chain rule : $p(x_1,...,x_n) = p(x_1)p(x_2|x_1)\\cdots p(x_n|x_1,\\cdots,x_{n-1})$ 2<sup>n</sup>-1 paramters\n",
    "- Bayes' rule : $p(x|y) = \\frac{p(x,y)}{p(y)} = \\frac{p(y|x)p(x)}{p(y)}$\n",
    "- Conditional independence : $ x\\perp y|z \\implies p(x|y,z) = p(x|z) $\n",
    "- Markov assumption(사건은 바로 전 사건에만 종속적)\n",
    "    - $p(x_1,...,x_n) = p(x_1)p(x_2|x_1)p(x_3|x_2)\\cdots p(x_n|x_{n-1})$\n",
    "    - 2n-1 paramters\n",
    "\n",
    "Autoregressive model : 전 사건들로부터 현재 사건 parameter 추정\n",
    "- 사건들을 ordering하는 방법, 얼마 전까지의 사건을 이용할 것인지에 따라 다른 결과\n",
    "    - ex) Markov assumption : 바로전 사건만 이용 AR1 model\n",
    "    - NADE(Neural Autoregressive Density Estimator)\n",
    "        - $p(x_i|x_{1:i-1}) = \\sigma(a_ih_i+b_i)$ where $h_i = \\sigma(W_{<i}x_{1:i-1} + c)$\n",
    "        - $p(x_1,...,x_{784}) = p(x_1)p(x_2|x_1)\\cdots p(x_{784}|x_{1:783})$ explicit model\n",
    "    - Pixel RNN : $p(x) = \\prod_{i=i}^{n^2}p(x_{i,R}|x_{<i})p(x_{i,G}|x_{<i},x_{i,R})p(x_{i,B}|x_{<i},x_{i,R}, x_{i,G})$\n",
    "    - row LSTM : 해당 pixel의 위에 있는 pixel들의 정보 이용\n",
    "    - Diagonal BiLSTM : 일렬로 늘어놓고 해당 pixel 이전의 모든 pixel들의 정보 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-professional",
   "metadata": {},
   "source": [
    "#### Lecture 2. Generative model 2\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-establishment",
   "metadata": {},
   "source": [
    "Autoencoder 는 generative model이 아니지만<br> variantional autoencoder는 generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-smell",
   "metadata": {},
   "source": [
    "Variational inference (VI)\n",
    "- posterior 분포와 가장 잘맞는 variational 분포 최적화가 목적\n",
    "- KL divergence 를 최소화, posterior 분포를 모르는 상태에서도 ELBO를 최대화함으로써 가능 \n",
    "\n",
    "$E_{q_{\\phi}(z|x)} \\left[ ln\\frac{p_{\\theta}(x,z)}{q_{\\phi}(z|x)} \\right]$ = \n",
    "$E_{q_{\\phi}(z|x)} \\left[ p_{\\theta}(x,z) \\right] - D_{KL}(q_{\\phi}(z|x)||p(z))$ =\n",
    "Reconstruction Term - Prior Fitting Term\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-damages",
   "metadata": {},
   "source": [
    "Variational Auto-encoder\n",
    "- intractable model : likelihood 계산 어려움\n",
    "- fitting term 이 반드시 미분가능해야함\n",
    "- Adversarial Auto-encoder : 임의의 latent distribution 활용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-regression",
   "metadata": {},
   "source": [
    "GAN (Generative Adversarial Network)\n",
    "- Fixed descriminator로 generator를 학습하는 것이 아니라 decsriminator가 generator로 학습하기 때문에 generator가 더 좋은 성능의 이미지를 만들수 있게 됨\n",
    "    - $\\underset{D}{max} V(G,D) = \n",
    "    E_{x\\sim p_{data}}\\left[logD(x)\\right] + E_{x\\sim p_G}[log(1-D(x))] $ : discriminator\n",
    "    - $D^*_G(x) = \\frac{p_{data}(x)}{p_{data}(x) + p_G(x)}$ : optimal discriminator\n",
    "    - $\\underset{G}{min}V(G,D) = E_{x\\sim p_{data}}\\left[logD(x)\\right] + E_{x\\sim p_G}[log(1-D(x))] $ : generator\n",
    "    - $2D_{JSD}[p_{data}, p_G] - log4 $ : optimal generator\n",
    "- info-GAN : 보조 랜덤 class를 image와 함께 삽입\n",
    "- text2image : 문장이 주어질 때 이미지 생성\n",
    "- cycle-GAN : cycle-consitency loss 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-chrome",
   "metadata": {},
   "source": [
    "#### peer session\n",
    "> attention & transformer 논문 review\n",
    "> 차주 moderator : 이종혁"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-dakota",
   "metadata": {},
   "source": [
    "#### 개인 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-company",
   "metadata": {},
   "source": [
    "Attention\n",
    "- 산재되어 있는 정보 중 지각가능한 타정보를 무시하며 선택적으로 집중하는 행동, 인지 과정\n",
    "- 한정된 인지 과정에 대한 할당\n",
    "- Topdown (전전두엽 : prefrontal cortex) / Bottom Up (뇌간 : brain stem)\n",
    "- Deep Learning에 첫 도입은 이미지 분야 boltzman machine(2010)이나 묻힘\n",
    "- Neural Machine Translation(2015) 에서 Encoder-Decoder Network가 자연어처리에 도입\n",
    "    - RNN의 문제점 : 길이가 길어지면 vanishing gradient\n",
    "    - 전체 문장을 하나의 고정된 벡터에 encoding 하지말고, vector들의 sequence로 encoding 후 subset을 골라 decoding\n",
    "    - context vector 를 생성하여 RNN으로 생성된 annotation과 가중치의 곱으로 정의함\n",
    "    - decoder에서 attention mechanism을 사용하여 모든정보를 하나의 벡터로 encoding 하지 않아도 되게 만듬\n",
    "    - 계산과정\n",
    "        - query와 key 선택, 가중치를 구하기 위해 유사도 계산(dot product, detector,..)\n",
    "        - softmax function으로 normalize\n",
    "        - 해당 value와 가중치를 곱하는 연산\n",
    "- attention의 세가지 방법        \n",
    "    - encoder-decoder attention : encoder -> decoder\n",
    "    - self-attention : 입력과 출력이 같은 상황에서 연결가중치 판단(machine reading)\n",
    "    - masked decoder self-attention : 입력과 출력은 같으나 단방향(주로 과거에서 미래 예측)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-andorra",
   "metadata": {},
   "source": [
    "Transformer - Attention is all you need(2017)\n",
    "- encoder self-attention / encoder-decoder attention / decoder masked self-attention 사용\n",
    "- self-attention : query,key,value로부터 score vector 생성\n",
    "- 기존 모델의 단점\n",
    "    - RNN : vanishing gradient, serial 구조(전단계 처리 필수, 연산이 느림)\n",
    "    - 1D Conv CNN : kernel size 설정이 어려움, 멀리있는 단어끼리는 상호작용이 제한됨\n",
    "- Transformer의 특징\n",
    "    - key, query, value들이 동일한 vector\n",
    "    - self-attention을 stack하여 nonliear하면서 성능이 우수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-rugby",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "virtual-wheel",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
