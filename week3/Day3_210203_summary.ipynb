{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "elect-elephant",
   "metadata": {},
   "source": [
    "#### Lecture 1. CNN basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-longitude",
   "metadata": {},
   "source": [
    "Convolution : 신호 체계에서 자주 쓰이던 기법\n",
    "- continuous : $(f*g)(t) = \\int f(t-\\tau)g(t)d\\tau = \\int f(t)g(t-\\tau)d\\tau $\n",
    "- 2D image : $\\sum_m \\sum_n I(m,n)K(i-m,j-n) = \\sum_m \\sum_n I(i-m, j-n)K(m,n)$\n",
    "\n",
    "- 보통 이미지는 width x height x (RGB) tensor로 표현\n",
    "- 고정된 크기의 convolution filter(kernel) 연산을 통해 특징 추출\n",
    "    - ex) 32x32x3 ==>(conv) 28x28x4  이려면 conv filter 4x5x5x3\n",
    "- convolution and pooling : feature extraction // fully connected : decision making\n",
    "    - 학습시킬 parameter의 숫자가 많을수록 학습이 어려움 generalized performance 낮아짐\n",
    "    - convolution filter는 sharing parameter이므로 parameter 숫자가 압도적으로 적음\n",
    "    - fully connected 의 비중이 낮아지는 추세\n",
    "- stride : convolution 연산 수행 간격\n",
    "- padding : 차원을 맞추기 위해 정해진 값으로 메꿔줌\n",
    "- 1x1 convolution : 깊이는 증가시키면서 parameter 숫자는 감소시킴, dimension reduction\n",
    "\n",
    "과제 및 실습\n",
    "\n",
    "- https://colab.research.google.com/drive/1r6i0sP1oH5oEC5VNrgFuFSiQgICaWr64?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-luther",
   "metadata": {},
   "source": [
    "#### Lecture 2. Modern CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-salem",
   "metadata": {},
   "source": [
    "AlexNet (2012) - 8layers (16.4% error)\n",
    "- ImageNet Large-Scale Visual Recognition Challenge(ILSVRC) 대회에서 두각\n",
    "- 11x11x3 filter, 5 convolutional layers, 3 dense layers\n",
    "- ReLU(Rectified Linear Unit) Activation 사용(nonlinear, vanishing gradient 극복)\n",
    "- 2GPU 사용, Data augmentation, Dropout 활용\n",
    "\n",
    "VGGNet (2014) - 19layers (7.3% error)\n",
    "- 3x3 convolution filters, 1x1 convolution for fully connected layers, dropout(p=0.5)\n",
    "- receptive field(하나의 filter에 적용되는 input의 크기) 는 filter 크기에 비례\n",
    "- 3x3 conv 두번의 receptive field = 5x5 receptive field, parameter 수는 전자가 적음\n",
    "\n",
    "GooleNet (2014) - 22layers (6.7% error)\n",
    "- Network in Network(NiN) 비슷한 네트워크 구조가 반복됨\n",
    "- inception block : input을 여러개로 쪼개, 1x1 conv를 수행함\n",
    "- parameter No.   AlexNet(60M) < VGGNet(110M) >>> GoogleNet(4M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-pottery",
   "metadata": {},
   "source": [
    "ResNet (2015) - 152layers  (3.57% error)\n",
    "- training error와 test error사이의 간극, layer가 깊어질수록 학습이 부진한 한계가 있었음\n",
    "- identity map을 더해 skip connection 효과 > layer가 깊어져도 학습\n",
    "- (3x3 conv + batch norm + relu + 3x3 conv + batch norm)(input) + input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-gospel",
   "metadata": {},
   "source": [
    "DenseNet (2017)\n",
    "- ResNet에서의 더하기 대신에 concatenation 사용\n",
    "- transtion block(batch norm + 1x1 conv + 2x2 pooling)을 사용해 parameter 팽창 억제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-diamond",
   "metadata": {},
   "source": [
    "#### Lecture 3. Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-highway",
   "metadata": {},
   "source": [
    "Semantic Segmentation - 화면을 인식하고 물체를 구분\n",
    "- fully convolutional network (conv / conv / flat / dense ==> conv / conv / conv)\n",
    "- parameter 숫자 동일 \n",
    "    - 4x4x16(input) -> 256(flat) -> 10(dense) # parameter : 4x4x16x10 = 2,560\n",
    "    - 4x4x16 -> 10  # 4x4x16(filter) x 10(layer) = 2,560\n",
    "- FCN은 어떤 사이즈에도 돌아가지만 output dimension이 감소하게됨 => space dimension 키우기\n",
    "    - Deconvolution(conv transpose) : convolution의 역은 아니지만 parameter숫자 파악에 도움\n",
    "\n",
    "Detection - 이미지안에서 물체 찾기\n",
    "- R-CNN : image를 2,000 개 영역으로 추출하여 각각의 영역에 AlexNet 적용, SVM으로 분류\n",
    "- SPPNet - 각각의 image를 모두 합쳐서 CNN 한번만 돌림\n",
    "- Fast R-CNN, Faster R-CNN(Region proposal network도 학습시키자)\n",
    "    - RPN parameter\n",
    "        - 3 region sizes(128,256,512) x 3 ratio(1:1, 1:2, 2:1)\n",
    "        - 4 bounding box regression paramter (Xh, Xl, Yh, Yl)\n",
    "        - 2 box classification (useful or not)\n",
    "- YOLO - 훨씬 빠름, image 한 장에서 별도의 구역을 나누지 않고 바로 예측\n",
    "    - S x S x (B x 5 + C) (s : cell #, b: bounding boxes #, C : class #, 5 : x,y,w,h, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-parcel",
   "metadata": {},
   "source": [
    "#### Lecture 4. CNN - dog classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-triumph",
   "metadata": {},
   "source": [
    "실습 자료\n",
    "- https://drive.google.com/file/d/1iullekfVWS-2sVtZD_pOkeUzxf2Oga-Y/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-nursing",
   "metadata": {},
   "source": [
    "google images download를 이용하여 자신만의 데이터셋을 만들자"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
