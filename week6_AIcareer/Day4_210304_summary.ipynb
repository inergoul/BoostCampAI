{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "million-courtesy",
   "metadata": {},
   "source": [
    "#### Lecture 1. AI 와 Quant Trading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-water",
   "metadata": {},
   "source": [
    "1. 퀀트 트레이딩 소개\n",
    "- 트레이딩 업계는 지적재산권을 매우 중시\n",
    "- 실제 딥러닝 리서치가 활용되는 예는 아직 드뭄\n",
    "- 투자는 장기간 / 트레이딩은 상대적으로 단기간\n",
    "- Quant - Quantitative(계량적) trading, 모델 기반, 데이터 기반 접근\n",
    "- ex1) arbitrage : 하나의 상품을 싼 곳에서 사서 비싼 곳에서 팜, 속도 경쟁\n",
    "- ex2) market making : 매수 주문과 매도 주문을 동시에 내서 유동성을 공급\n",
    "- ex3) statistical arbitrage : 미래 가격의 변화를 예측해서 거래, 데이터 기반 접근이 필수\n",
    "    - 선형 회귀가 모델의 대다수,머신러닝/딥러닝 추가 / 포트폴리오(모델 기반)\n",
    "\n",
    "2. 트레이딩의 실효성\n",
    "- 효율적 시장 가설 : 가격은 상품에 대한 모든 정보를 포함하고 있으므로 장기적인 초과수익 달성은 불가능\n",
    "- 상품의 새로운 정보가 가격에 포함되기 위해선 누군가 거래를 해야함\n",
    "- 성공 기준이 우리의 직관과 다름, 엄청나게 많고 작은 예측들을 하므로 성공률이 51%만 되어도 이득을 볼 수 있음\n",
    "- 시장을 예측하는 것은 너무 어려움\n",
    "    - 시장에 영향을 주는 원인 중 우리가 볼 수 있는 것은 극히 일부\n",
    "    - 시장의 특성이 계속 변함 : 참가자가 접근 방법을 고도화하고 계속 변동, 모델에 대한 피드백\n",
    "    - 딥러닝이 어려운 이유 : 오버피팅의 위험이 너무 큼, 인샘플 에러를 낮추는 것은 쉽지만 기존 데이터 셋 에서 오버피팅을 극복해도 미래에 오버피팅이 일어날 지 장담할 수 없음\n",
    "    - 아직도 선형회귀가 대세\n",
    "    \n",
    "3. 리서치 과정에서 주의점\n",
    "- 프로덕션 시스템과 백테스트 시스템의 차이\n",
    "- 마켓 임팩트\n",
    "- 데이터 스누핑\n",
    "\n",
    "4. 개발자 경력이 도움되는가\n",
    "- 남들의 프로세스를 개선하고 플랫폼화하는 과정에서 내 아이디어 도입 가능\n",
    "- 수학적 모델링 기법/알고리즘과 구현사이의 경계가 확실하지 않음\n",
    "- 리서치하다 답답할때 플랫폼 개선하면 도움되지만 리서치 과정의 느린 피드백에 익숙해지는 과정이 필요\n",
    "- 내가 푸는 문제에 대해 결국 깊이 이해하여야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-somalia",
   "metadata": {},
   "source": [
    "#### Lecture 2. AI & Ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-woman",
   "metadata": {},
   "source": [
    "1. AI & Individuals\n",
    "- 편향(bias)\n",
    "    - input data의 편향이 모델의 판단에 반영됨\n",
    "    - ML model의 의사결정에 미치는 속성이 세분화되어 있기 때문에 차별이 발생할 수 있음\n",
    "    - redlining : 빈곤층과 소수 커뮤니티에 불리한 서비스와 상품에 대해 엄격한 기준을 설정함으로써 나타남\n",
    "    - bias metrics : target concept에 특정 속성이 나타날 확률을 찾음\n",
    "- 개인정보(privacy) : privacy from snoopers / privacy from contacts / privacy from authorities\n",
    "\n",
    "2. AI & society\n",
    "- Social Inequality\n",
    "    - 중요한 의사 결정에 AI가 사용되며 편향된 의사 결정 가능\n",
    "    - low-tech, 단순 반복 업무에서 일자리를 빠르게 대체함\n",
    "    - worker 간의 상호 연대가 불가능해지며, 가격 / 팁등에서 기존보다 worker가 손해를 봄\n",
    "- Misinformation\n",
    "    - GPT-3 같은 거대 언어 모델 / Deepfake 이미지 생성 / Identity swap\n",
    "    - Manipulation detection\n",
    "\n",
    "3. AI & Humanity\n",
    "- AI for Health\n",
    "    - vision detecting 을 통해 의료 기술에 도움(early detection)\n",
    "    - 지속적인 care 및 관리\n",
    "    - covid-19 diagnose\n",
    "- AI for Environment\n",
    "    - AI 모델 학습 및 평가 시에 CO2 배출 및 전력소비가 엄청남, 효율적인 AI 설계 필요\n",
    "    - 전기차, 운행 효율 개선에 AI 사용\n",
    "    - urban computing으로 동선절약 되도록 경로 선택\n",
    "    - farm / factory의 energy 효율적 운영\n",
    "    - climate prediction modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-junior",
   "metadata": {},
   "source": [
    "#### peer session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-necklace",
   "metadata": {},
   "source": [
    "1. 유클리디언 거리, 코사인유사도를 통한 유사도 측정의 차이는 무엇이 있을까?\n",
    "- 유클리디언 거리는 공간상에서 실제 거리를 측정하기 때문에 연속형 자료에 활용 가능\n",
    "- 하지만, Categorical Data에는 이러한 거리 기반으로 측정하는 것이 옳지 않을 수 있음\n",
    "- 예를 들어, 인코딩 되어있는 seq벡터가 있다고 생각해보면, 해당벡터의 크기(norm)는 해당 seq의 의미를 고려하는데 있어서 활용되면 안 됨\n",
    "- 텍스트 데이터는 norm으로 표준화(벡터의 크기 무시)하고 각도만을 고려하는 코사인 유사도 사용\n",
    "- 유클리드 거리는 항상 양수값만 나오므로 반대 방향 표현 불가\n",
    "\n",
    "2. 과적합을 막기 위한 딥러닝 기법들\n",
    "- L1 L2 regularization : 가중치 규제, 비용함수에 가중치 들의 절대값 합계(L1) or 제곱합(L2) 추가\n",
    "    - L2 regularization : weight decay\n",
    "- DropOut : 학습과정에서 신경망의 일부를 사용하지 않는 방법\n",
    "    - 특정 뉴런에 너무 의존적이게 되는 것을 방지하고, 랜덤 선택에 의한 앙상블 효과를 줌\n",
    "- CrossValidation : 교차 검증(일부 학습데이터를 validation set으로 과적합 검증)\n",
    "- 모델 parameter 축소 : 출력 직전 노드, 은닉층 노드 수 줄이기\n",
    "- batch normalization : 모든 노드가 각 레이어를 통과한 미니배치의 출력을 표준정규분포로 정규화함\n",
    "- data agumentation : 데이터 증식\n",
    "- EarlyStopping 너무 많은 epoch가 과적합의 요소이므로 적절한 시점에 학습 종료\n",
    "- Label Smoothing\n",
    "\n",
    "3. train, valid, test set을 따로 나누는 이유\n",
    "- train set으로 학습시키면서 valid set으로 점검\n",
    "- 우리는 valid set을 이용해 hyper parameter tuning도 할 수 있을 것이고, test에 적합화된 모델이 생성됨\n",
    "- test data는 unseen data로서 이것을 잘 predict 하는 것이 목적이기 때문에 train에 활용되면 안됨(data leakeage problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-mortality",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
