{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surrounded-desperate",
   "metadata": {},
   "source": [
    "#### Lecture 1. 서비스 향 AI 모델 개발하기 by 이활석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-array",
   "metadata": {},
   "source": [
    "1. 서비스 향 AI 모델 만들기\n",
    "- 수업/학교/연구에서는 정해진 데이터셋/평가 방식에서 더 좋은 모델을 찾음\n",
    "- 서비스 개발 시에는 학습 데이터셋, 테스트 데이터 셋, 평가 방법도 없이 서비스 요구 사항만 있는 경우가 많음\n",
    "- 서비스 요구사항으로부터 학습 데이터셋의 종류, 수량, 정답 에 대한 설정이 필요\n",
    "- 모델하나에 대한 정답은 모델 설계와 맞물려 있음\n",
    "- 테스트 데이터셋 / 테스트 방법 준비\n",
    "    - 개발환경(offline) 정량평가와 실 서비스 적용시(online) 정량평가는 다른 결과 가능\n",
    "    - offiline 정량 평가로 후보 pool을 형성하고 정성 평가로 면밀 분석 후 출시 버전 선택\n",
    "- 모델 요구사항 도출 : 목표 qps, 처리 시간, 목표 정확도, serving 방식, 장비사양\n",
    "- 기술팀 구성 : modeler, data curator, tool developer, model 품질 매니저\n",
    "- model engineering : serving HW 로 모델을 최적화\n",
    "\n",
    "2. 조언\n",
    "- Model Engineering / Tool / Serving은 개발력이 많이 필요한 일이므로 개발자로서 이점\n",
    "- 모델링 전문성도 중요하지만 해당 업무가 자동화(AutoML)되니 주변으로 역량을 확대할 것\n",
    "- AI 기술 발전 속도가 매우 빠르므로 트렌드에 민감해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-reply",
   "metadata": {},
   "source": [
    "#### Lecture 2. AI 시대의 커리어 빌딩 by 박은정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-count",
   "metadata": {},
   "source": [
    "1. Careers in AI\n",
    "- 논문을 쓰고 싶다면 학교 / 상품과 서비스를 만들고 싶다면 회사\n",
    "- AI 회사 : AI for X(AI가 보조수단) / AI centric(AI로 새로운 비즈니스 창출)\n",
    "- AI Engineering : AI/ML modeling은 팀 전체 업무의 일부일뿐\n",
    "- 각 포지션의 공통적 표현은 정립이 덜 되어 있으며 모집공고를 꼼꼼히 읽어보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-interview",
   "metadata": {},
   "source": [
    "2. How to start my AI engineering career\n",
    "- 자신에 대한 이해\n",
    "    - fundamental 한 학문을 좋아하는 사람인가?\n",
    "    - 결과가 나오지 않아도 꾸준히 팔수 있는 인내심이 있는가?\n",
    "    - 비즈니스에 관심이 있는가?\n",
    "    - 세상에 상용화 되는 모델을 만들기를 바라는가?\n",
    "- 인턴십, AI competition(kaggle), 최신 논문 재현\n",
    "- 배울 수 있는 사람 / 풍부한 데이터, 계산 자원 / 집중할 수 있는 문화\n",
    "- 범위를 확장해 나가면서 필요한 것을 하나하나 챙겨가기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-accountability",
   "metadata": {},
   "source": [
    "3. AI에 필요한 역량\n",
    "- 컴퓨터 공학에 대한 기본적인 이해와 소프트웨어 엔지니어링 능력\n",
    "- 최신 기술을 빠르게 습득하기 위한 영어 능력\n",
    "- Soft-skill : GRIT / Humility / Passion / Teamwork / Kindness\n",
    "- 모든 것을 잘하려고 하기보다 팀에 기여할 수 있는 나만의 엣지를 키워라"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-testimony",
   "metadata": {},
   "source": [
    "#### Peer session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-introduction",
   "metadata": {},
   "source": [
    "1. Transformer의 구조를 attention을 기반으로 설명해주세요. ( Attention 3개를 생각하며 설명해보기 )\n",
    "- Encoder에서 이루어지는 self-attention (동일한 출처의 query, key, value vector를 활용하여 Attention Distribution을 구하는 구조)\n",
    "- Decoder에서 이루어지는 Masked-Self attention\n",
    "- Decoder에서 이루어지는 Enocder-Decoder Attention (query 벡터는 Decoder로부터, 나머지 key와 value는 Encoder로부터)\n",
    "> 참고 : https://wikidocs.net/31379\n",
    "\n",
    "2.딥러닝 가중치 초기값이 0이라면 어떤 문제가 생길까요?\n",
    "- 순전파시 입력층의 가중치가 0이니, 이것과 입력값을 곱하면, 모든 값이 0이 되어버립니다.\n",
    "- 이렇게되면 입력층의 값이 무의미해지고, 역전파시에도 모든 매개변수가 똑같이 갱신되어 버린다. \n",
    "    - (참고 : Xaiver 가중치 초기화, He 가중치 초기화)\n",
    "3. 여러개의 LSTM 단을 여러 층으로 쌓을 수 있을까, 그렇다면 성능은 기존보다 더 좋을까?\n",
    "- LSTM을 여러 층으로 쌓을 수 있다 (우리가 알고있는 MLP의 형태처럼) => 이는 Stacked-LSTM이라고 부르는 구조이며, Long-term Dependancy가 별로 문제되지 않는 Task를 수행할 때 적용해볼 수 있고 이 경우 단층 LSTM보다 성능이 좋다고 알려져있다.\n",
    "4. DataLoaer에서 num_workers는 어떤 역할을 하는 파라미터인가?\n",
    "- 학습 도중 CPU의 작업을 몇 개의 코어를 사용해서 진행할지에 대한 설정 파라미터\n",
    "5. 어느 설명변수(x)와 반응변수(y) 간의 상관계수가 0에 가까운 값이었지만, 모델 예측에 있어서 유의한 변수로 나타날 수 있습니다. 어떻게 이런 경우가 발생할까요?\n",
    "- 상관계수로는 변수의 유의성을 판단할 수가 없다. 상관계수는 단지 x와 y 간에 얼마나 선형관계가 뚜렷한지를 나타내는 지표일 뿐이기 때문이다. 예를 들어, x와 y간의 산점도 분포가 이차함수에 가까운 형태를 띈다고 가정해보면 두 변수 사이의 상관계수는 매우 낮은 값이지만, 단순 polynomial regression 모델을 적합하게 되면 자료를 잘 설명할 수 있으며 x가 유의한 변수로서 기능할 수 있기 때문이다.\n",
    "6. 경사하강법을 초중생에게 가르쳐야 한다면 뭐라고 설명하겠는가?\n",
    "- 산에서 조난을 당했을 때 산의 맨 아래로 내려오고 싶은 상황이라고 가정해보자. 어느 방향으로 내려가야 할지를 생각해보면 무조건 내리막길로 내려가야 하고(하강법), 그 중에서도 가장 가파른 경사를 찾아 내려가야 하는데 이 때 사용할 수 있는 것이 미분값이다.  그리고 이 때 보폭의 크기를 learning rate라고 이해할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
